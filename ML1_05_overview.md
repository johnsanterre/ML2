# ML1 Week 5: Regression Methods: From Linear to Logistic

## Overview
This week progresses from linear regression through logistic regression, exploring both direct and iterative solutions, and extending to multiclass classification.

## Learning Objectives
By the end of this session, students will:
- Master Ordinary Least Squares (OLS)
- Understand iterative optimization methods
- Implement binary logistic regression
- Extend to multiclass classification
- Apply gradient descent variations

## Topics Covered

### 1. Linear Regression Solutions
- Ordinary Least Squares
  * Direct solution method
  * Matrix formulation
  * Computational considerations
  * Limitations
- Iterative Approach
  * Gradient descent formulation
  * Step size selection
  * Convergence criteria
  * Advantages over direct solution

### 2. Binary Logistic Regression
- Problem Formulation
  * From linear to logistic
  * Sigmoid function
  * Probability interpretation
  * Decision boundaries
- Gradient Descent Solution
  * Loss function
  * Gradient computation
  * Parameter updates
  * Optimization process

### 3. Multiclass Extension
- One-vs-All Approach
  * Multiple binary classifiers
  * Decision boundaries
  * Implementation considerations
- Softmax Regression
  * Multinomial logistic regression
  * Cross-entropy loss
  * Gradient computation
  * Class probabilities

### 4. Optimization Methods
- Gradient Descent Variations
  * Batch gradient descent
  * Stochastic gradient descent
  * Mini-batch approach
- Implementation Details
  * Learning rate selection
  * Batch size considerations
  * Convergence monitoring
  * Performance trade-offs

## Key Takeaways
1. OLS provides direct solution for linear regression
2. Iterative methods enable more complex models
3. Logistic regression handles classification
4. Multiple approaches for multiclass problems

## Practical Exercises
1. Implement OLS solution
2. Build iterative optimizer
3. Create binary classifier
4. Extend to multiclass problems 